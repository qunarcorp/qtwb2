---
typora-root-url: ./..
---

## 1.背景介绍
### 1.1去哪儿网CICD建设
​        在竞争激烈的互联网行业，高效持续的交付能力是我们抢占市场先机的重要基础，由此CICD应用而生。所谓CICD即Continuous Integration、Continuous Delivery，是指通过自动化的手段将代码持续的集成打包并持续的部署验证，它主要的功能就是保障技术人员的产出能够快速被验证、被交付，从而保证业务价值、产品需求能够快速、持续可靠的交付到用户手上。

​        去哪儿网作为典型的互联网旅游电商平台，有着旅游行业业务复杂、业务需求多变的特点。为了更好的应对业务的快速变化所带来的挑战，去哪儿网结合自身的业务特征，开发了自己的CICD系统，确保应用高质量且快速的持续集成和交付。

​        在去哪儿，我们采用微服务架构，每个微服务我们称之为应用，每个应用都有唯一的标识即appcode，所有的研发过程都是围绕appcode进行，同样CICD也不例外，以下是我们的基本架构图：

![image](/images/deploy_dashboard/deploy_dashboard_6.png)

如上图所示，去哪儿网CICD体系主要由应用画像、代码/仓库管理，质量控制、流水线、编译/部署以及k8s/kvm六个模块构成。其中：

* 应用画像：我们的CICD是以单个应用为维度建设的，而应用画像便是保存了该应用的配置信息以便交付运维使用，包括运行时配置(环境、主机数、CPU、内存等)，发布配置(代码地址、自定义发布脚本、发布参数等)，依赖配置(负载均衡、应用监控、DB白名单等)
* 代码/仓库管理：主要管理应用代码、基础镜像、依赖源，同时也保存持续集成生成的镜像、二进制产物包等等
* 质量控制：在CICD过程我们集成了质量控制体系用于CICD过程质量保障，包括丰富的质量检查手段：code review检查、静态代码扫描、安全扫描、单元测试、自动化测试、覆盖率检查等，这些检查手段是通过代码push自动触发的，同时会有及时的消息反馈，减少了人力成本；还包括质量门禁模块，用于将检查手段集成到发布阶段，保障检查手段的真实有效执行及被解决。
* 编译部署&流水线：我们的发布系统是一个独立的系统，编排调度模块完全自研，调度Jenkins集群执行具体的构建打包和部署逻辑，公司内的开发测试同学可以通过输入分支信息进行部署发布，这样保证了线上发布的人工控制；同时我们依托于argo自研了流水线服务，将研发过程的构建打包验证串联起来，包括质量检查、代码校验、构建打包、环境创建更新、部署发布、业务验证等来，并实现code-push自动触发，执行结果自动IM消息反馈，保障了开发过程的快速集成、持续验证、无人工干扰；
* k8s/openstack：最终我们的服务根据业务属性不同部署我们自己的私有云上，包括k8s和openstack

### 1.2容器化落地

​       随着云原生技术的兴起，去哪儿网从2021年初也开启了自己的容器化落地之路，通过一些列的改造适配迁移，目前我们已经实现了80%左右的应用容器化，在基础设施容器化章节中我们已经介绍了在落地过程中CICD系统的改造，但是当时的改造主要还是在交付逻辑上的改造，用户交互流程上只是适配，而且我们的交付模式采用了IP动态分配的方式，这种方式跟kvm IP固定方式完全相悖，因此我们之前基于kvm建设的CICD交付流程对于开发过程的无感知流水线冲击不大，但是对于线上发布这种需要全方位信息观测的动作就造成了较大的冲击。经过一段时间的运行，问题逐渐暴露，先来看下我们以前的交付界面：

![image](/images/deploy_dashboard/deploy_dashboard_8.png)

由上图我们不难发现主要存在以下几个问题：

- 整体进度不直观：kvm发布我们可以很直观的查看到发布的进度，但是对于容器发布（每次发布pod重建，同时采用双deployment部署，一增一减、先增后减）却无法很直观的了解当前的整体进度、新老版本的比例、单pod的进度等；
- 发布异常定位慢：当前模式对于kvm来说，发布过程开发同学是提前通过跳板机远程登陆到主机后，单机查看日志信息；但是当容器发布时，容器的名称是动态生成的，开发无法提前登陆，这样就会导致开发无法实时的监控异常，出现问题发现就会滞后很可能造成故障；
- 信息分散：其实由上图可以看出我们的发布过程只能看到机器的部署进度，然后发布是一个非常重的动作，是将我们的成果交付用户的最后一道防线，也是很容易产生问题的环节，统计我们历年的故障，将近50%以上的故障都是发布引起的，所以一定要做好质量保障，主要是发布前的验证测试以及发布过程的及时观测。在去哪儿我们是要求发布之后持续观察监控30分钟的，但是从上图中我们并不能看到监控信息，开发同学每次需要到监控系统打开关注的面板，然后再进行发布，无形中又为发布增加了负担；
- 关联问题无法发现：发布某个应用有时候可能自己没有问题，但是会造成上游服务异常，比如说我们接口向下不兼容，但是别人却依赖了我们的老版本而没有同步修改，因此怎么能让本次发布影响的所有应用都被可观测，这又是我们需要考虑的重点；

​        基于以上问题，我们跟项目流程管理同学、业务同学一起确定了发布流程并把流程固化在了发布系统中，新增了仪表盘、发布过程异常信息汇总，并依托公司的应用拓扑图，将当前应用及其上下游应用的异常日志、监控报警有机整合起来，让整个发布过程更加透明，用户能够实时观测到发布进度、异常日志和异常报警，从而快速做出决策，减少故障，及时止损。

## 2.实践框架

​        由上述的分析可知，我们主要解决的是线上发布的可观测性问题，那么就需要知道这个过程需要观测哪些内容，其实由云原生的可观测性我们也可以知道，主要包含：

- 报警：通常变更是导致问题的最直接原因，因此当我们发布的时候需要实时关注报警信息，这样才能最快的发现变更导致的问题并快速的决策恢复；
- 监控：有的同学可能会说报警不就够了吗，为啥还要看监控，其实报警是一个相对来说比较严格的策略，为了提升报警的有效性，降低日常报警的干扰率和开发同学的运维成本，我们并不希望大家将所有的指标波动都设置为报警；而且一个应用的变更可能影响的链路非常长，比如说有一条链路A->B->C->D->E，当A变更时，可能是E的指标发生了波动，因此在去哪儿业务同学会将关心的指标聚合成几个重要的面板，同时对这几个面板进行核心标记，这样当这块业务中的任何一个应用变更时，只需要关注这些核心面板即可，大幅提升了定位问题的速度；
- 日志：由于指标报警的滞后性（在去哪儿指标是1分钟收集一次，报警自定义，通常是5分钟报出来）和灵敏度（指标更多的是业务的反应，单台机器的异常可能无法在业务指标上快速体现），在发布过程开发同学需要实时查看变更pod的日志；然而有些变更可能不体现在单台上，因此我们也需要关注应用整体的异常日志变化量；
- 链路：正如上文分析，微服务架构虽然大家都可以独立运行，但是又相互依赖，而且变更通常可能导致的是上下游、甚至多层依赖的异常，因此我们需要关注变更应用以及整个链路的报警、监控、日志信息；
- 进度：线上发布是将老版本下线新版本上线的更新过程，而通常一个应用为了实现高可用都会部署在多集群，同时也会根据线上的QPS进行多POD部署，而且前文也提到我们是采用双deployment模式，先上线再下线，因此整个发布的过程是需要一定的时间的，那么我们就要对当前的进度可观测，因此我们需要了解当前整体的进度：新老版本的个数，单Pod的进度：在初始化或者OR更新等。

​       基于以上分析我们对发布过程进行了改造，目标是将发布过程应该关注的信息进行聚合，以便用户可以快速的做出决策，避免问题的扩大化，我们将其命名为发布驾驶仓，以下是我们的架构图：

![image](/images/CICD/dashboard1.png)

如上图所示，发布驾驶仓最终落地是在发布系统中，主要包含数据层、分析层、展示层；

### 2.1数据层

- 应用拓扑：基于负载均衡日志、rpc信息等提炼分析，生成应用间的依赖拓扑图，可以获取appcode的上下游信息，发布驾驶仓从此处获取本次发布影响的变更链路，确定影响的应用范围
- 监控控告警：基于grafana、graphite、icinga开发的公司级监控报警系统，发布驾驶仓从此处获取本次发布的核心面面板及影响应用的监控告警信息
- 异常日志：公司自研的基于kafka、hbase等的异常日志实时收集、分析系统，发布驾驶仓从此处获取单pod异常堆栈及影响应用的异常日志汇总信息
- 资源管理：k8s集群管理，发布驾驶仓跟其交互获取容器部署过程中的整体进度信息(批次信息、部署日志)、整体pod数变化以及每个pod的状态

### 2.2分析层

分析层主要是将数据收集之后进行分析汇总

#### 2.3.1拓扑分析

在发布过程我们会从应用拓扑中获取当前应用的上下游，并将这些应用及发布应用整合作为本次发布的变更影响范围

#### 2.3.2报警、监控、异常日志
![image](/images/deploy_dashboard/deploy_dashboard_2.png)

如上图所示，在容器发布进行到部署阶段后，系统会首先获取当前appcode的上下游信息，之后会轮询监控告警系统和异常日志系统，获取发布时间段内当前应用以及上下游应用的报警信息和异常日志信息，同时会计算报警增量、异常日志环比、增量等；后端分析汇总后传回前端，分别展示总体信息(报警总数、异常日志新增&环比)以及详细信息，并且在有报警和异常日志时，我们会自动跳转到对应tab页以进行更及时的提醒。

#### 2.3.3进度
![image](/images/deploy_dashboard/deploy_dashboard_5.png)

我们当前的容器发布采用的是双deployment的形式，发布过程中会新建一个deployment，分批次增加新版本的pod数目，在当前批次发布完成且通过检测后，会对应缩减原deployment的pod数；由此一增一减，先增后减，最终新deployment达到目标容器数，原deployment缩减到0并被新deployment替换。

双deployment带来了很多优势，比如易于控制，能够分批发布，能够及时暂停，安全性较高、扩展性强等；但同时也带来了一些问题，比如代码版本管理困难、中间状态不好控制等。由此在观测性上也带来了一些问题，比如用户反馈无法及时观测到新旧代码版本的pod数变化、整体发布进度(比如批次信息、发布状态等)。因此我们引入了仪表盘，实时展示新旧代码对应的pod数，以及整体发布进度信息。

![image](/images/deploy_dashboard/deploy_dashboard_4.png)

如上图所示，在发布过程中，发布系统会实时获取当前发布整体进度，包括发布批次、发布状态等，并实时watch pod变更，在有pod变更时，会按deployment、新旧代码版本重新计算pod数目，并回传给前端并展示。

#### 2.3.4展示层

最终我们会将以上获取到的信息及分析汇总结果展示给用户，包括：

- pod新老版本整体进度仪表盘，可以实时查看当前发布批次、发布状态、新旧版本pod数据等；
- 监控告警、异常日志的汇总信息，包括当前报警总数、异常日志类型总数、异常日志新增数、环比数等；
- 报警、异常日志详情tab:详细查看报警个数、报警指标、报警状态、异常日志类型、异常日志堆栈、环比增幅等。

通过以上这些，用户可以实时掌控整个发布过程，提升发布安全性，降低故障率，及时止损。

![image](/images/CICD/dashboard2.png)

![image](/images/deploy_dashboard/deploy_dashboard_10.png)

ps:上图数据为样例数据

## 3.难点坑点

### 3.1怎样精准识别关键信息

问题描述：发布驾驶仓的目的是建立发布过程的可观测性，按照上述实现路径我们将发布过程的信息进行了聚合，理想情况下可以解决用户的痛点，但是如果我们仅仅是把信息堆砌在一起，那么用户看到的就是一堆杂乱无绪的信息，不仅解决不了问题，严重甚至会对定位问题造成干扰，那么就失去了精准提醒、快速定位的意义

解决思路：

- **信息统计而不是明细罗列：**由上述分析可知我们变更期间需要观测指标、报警、异常日志等多种信息，而且通常情况如果此次发布变更产生问题，很可能会有级联报警、异常日志等，单独明细去看费时费力，因此我们提供了信息汇总，通过统计发布期间的异常日志、报警量总量变化、发布阶段和平时的环比对比等，让用户可以很直接的观测到发布带来的影响并做评估，同时我们也提供了报警和异常日志明细tab，每分钟定时刷新，而且当有增量变化是动态跳转tab，在交互上做到更佳智能；
- **链路诊断而不是单点观测**：俗话说牵一发动全身，经过这么多年的积累成淀，业务系统的关联关系是非常庞杂的，因此当一次发布变更时，不仅自己的信息非常多，影响的范围也可能会非常大，系统的雪崩也可能是这么来的，因此我们通过应用的拓扑依赖获取了应用上下游的依赖链路及应用自己的相关信息进行汇总，这样能够更大范围的观测变更的影响，更快速的定位变更的影响；
- **业务观测而不是资源分析：**其实在做发布驾驶仓时我们也调研了一些开源的devops产品，发现大部分的产品在容器发布过程的可观测性集成的是资源层面的监控，但是通常情况下业务变更对资源的影响较小，对业务的影响较大，因此我们获取了发布应用对应的核心监控面板（面板可能是该应用涉及的业务模块，也可能是该应用归属团队的业务大盘），并将该面板集成到发布过程，这样发布的同学可以高效的了解发布应用的影响，同时也解决了新同学学习核心面板、部分同学只关注自己应用变更的问题。

### 3.2怎样获取有效的异常日志

问题定位：技术同学应该都知道，为了问题定位或者处理特定case，系统一般都会打印许多日志，同样异常日志也会有很多，拿我们比较大的业务系统，10分钟就会产生上万条异常日志，但是这些日志有时候是系统运行所能容忍的，并不需要被关注，那么我们在发布阶段怎样获取发布的异常日志帮助业务同学定位问题呢

解决思路：

定义异常日志的优先级：我们根据日常收集到的异常日志进行了分组，比如代码异常（空指针、数组越界）、DB异常（慢查询）、redis异常（获取链接失败）、dubbo异常（限流异常）、http异常等，同时每组异常类型进行了优先级定义，包括P1/P2/P3/P4，如空指针、数组越界等为P1，那么发布驾驶仓只会获取P1级别的异常日志，这样当该异常日志有变化时，发布人员就可以及时的终止发布进行定位了。

## 4.总结展望

​      在去哪儿网云原生的途中，容器化被作为其中极其重要的一步，是去哪儿网云原生的前提和基石。通过容器发布驾驶舱项目的完成，将发布进度、应用及其上下游的异常日志和异常报警有机统合在一起，帮助业务线提升容器发布过程中的可观测性，发布人员可以实时掌握整个发布进程并及时决策，增强了容器发布的透明度，提升了发布的安全性。

​     后续我们将在以下两方面进行探索：

- 继续整合更多的决策信息，包括如负载均衡up_stream变更信息，并尝试引入决策算法，比如在出现特定异常日志、报警或者某些异常日志报警数目到达一定量后，自动挂起发布进度，并提示用户及时决策；
- 在发布驾驶仓进行埋点数据统计，比如发布过程是否查看监控面板、观测时长是否符合公司发布要求等，通过这种方式真正将规范落地到系统中。

