# 中间件容器化适配

## 1 背景

随着容器化技术的逐步成熟，越来越多的公司开始拥抱云原生技术。一方面容器化后扩容缩容更加灵活，能提升资源利用率、降低总体成本。另一方面，容器化后整体环境标准化程度提升，业务的发布、运维效率都能得到提升。经过慎重考虑和权衡，去哪儿网内部也决定全面容器化。

kvm和容器化差异较大，我们最终的目标是要在整个公司落地容器化，为云原生建设打下基础，所以我们需要在推动业务团队容器化之前做好中间件的容器化适配工作，屏蔽 KVM 和容器这 2 种不同环境的差异，降低业务团队容器化的成本。

## 2 实践路径

在本节中，我们会详细介绍基础架构团队在支撑业务团队容器化方面具体做出的准备工作，从业务直接使用的中间件组件到为了支撑容器化而新增的公共服务都会涉及。

### 2.1 组件梳理

首先，我们先简单介绍一些公司内部比较重要的组件，他们包括：

* 公共核心库，这是一个核心的接入层依赖包，用于项目自动接入公司的应用体系，可以为其他中间件提供应用、机器环境等基础信息。
* qconfig，公司内的配置中心，统一管理应用的配置，支持配置热更新。
* qmq，公司内的消息队列，主要处理业务相关的消息。
* qschedule，公司内的任务调度系统，用于业务统一管理定时任务。
* dubbo，公司内使用的 RPC 框架，包含了一些内部定制化的功能。
* redis & mysql client，公司内的数据源客户端，屏蔽了集群细节和具体 IP 地址，支持动态集群变更。

### 2.2 容器化环境特点

首先，我们从公司内部的虚拟机环境说起。使用虚拟机时，新项目上线或者是现有项目扩容，都需要开发人员预先提交机器申请，经过审批、交付获得机器后才能发布。如果项目本身对 JDK、tomcat 或其他软件有要求，还需要自行调整新机器的环境。虚拟机一旦交付，机器的 IP 和 hostname 基本就保持稳定了，发生变动的情况很少。虚拟机环境的项目发布时，发布系统选择的策略是一批批下线、更新、上线的策略，这个过程中提供服务的虚拟机是先减少再恢复正常。

容器环境整体上和虚拟机环境有一些明显差异。容器由 k8s 统一管理，不再需要业务同学提前申请了，业务同学在发布时确定好容器数量即可，发布时会由 k8s 自动创建出足够数量的容器。项目的容器环境也是预先定义好的，不再需要业务同学一台台单独调整。由于容器是发布时由 k8s 自动分配，所以机器 IP 和 hostname 都是随机的。在发布阶段，公司内的发布团队选择了双 k8s deployment 更新的模式，上线过程从容器数量上看变成了扩容、上线新版本、下线老版本、缩容老版本，整个过程中是提供服务的容器数量先增长再减少。

从上面的描述可以看出虚拟机环境和容器环境最大的差异有 2 点：

1. 容器化后 IP 和 hostname 都从相对稳定变成了完全随机
2. 项目发布从逐批替换发布变成了先扩容再缩容

### 2.3 适配核心思路

为了让业务服务能够迁移到容器化环境，中间件必须首先适配容器化环境，否则业务根本无法迁移。中间件适配容器化环境的核心问题有 2 个，中间件自身的正常运行和尽量屏蔽环境差异。由于环境的变化，很多中间件功能也都无法直接在容器化环境中运行，要让中间件功能适配容器化环境，能够适配的功能要尽量隐藏 2 种环境的差异，无法适配的功能需要考虑屏蔽或者重新根据容器化环境的特点设计功能。

#### 2.3.1 环境识别

无论是兼容不同环境还是针对不同环境单独重新设计功能，都需要先识别出不同环境，这是后续一切工作的基础。客户端需要识别不同环境，根据环境做相应的兼容操作，尽力屏蔽环境差异，保持对外接口行为的一致性。服务端也一样，除了尽力保持功能的一致性外，还需要针对无法兼容的功能单独设计开发对应的新功能。

那我们该如何做环境识别呢？目前公司里提供了 2 种方案。一种是请求一个统一的中心服务，这个中心服务根据 IP 返回对应的环境信息。另一种是在容器和虚拟机上添加一个描述文件，里面包含对应的环境信息。

在客户端中，为了减少外部依赖，提高可靠性，我们选择了描述文件的方式。由发布系统在发布时生成描述文件，描述文件中包含了当前的机房信息、环境信息等。之后再由我们的公共核心库读取描述文件统一对外提供环境识别的接口，由于其他公共组件库之前已经接入核心库，就不需要再自己做环境识别的工作了。

在服务端中，则需要根据具体的业务场景做不同的处理。对于直接和客户端交互的服务，通常客户端会主动汇报目标节点的环境信息，或者是在请求中带上环境信息，这种情况下服务端会直接使用客户端传递的环境信息，减少外部交互。而对于不会和客户端交互的服务端部分，则需要根据 IP 从中心服务上查询出对应的环境信息。

#### 2.3.2 适配思路

环境识别问题解决后，就要考虑各个组件中的各项具体功能如何适配了，要判断哪些功能能够兼容，哪些功能需要重新设计。我们之前总结了虚拟机和容器环境的 2 个主要差异点，可以看到影响比较大的主要是单机相关的部分，所以这里根据功能是否涉及单机分为 2 类来考虑。

对于非单机功能，由于不需要针对不同的单机做处理，所以能够识别环境后基本都可以屏蔽具体差异，提供一致的服务行为。

对于单机功能，由于组件较多，整体就比较复杂了。我们逐个分析了各个中间件里涉及单机的功能，下面是一些例子：

* 公共核心库和应用中心：主要涉及到单机的环境识别
* qconfig 配置中心：主要涉及到单机配置推送、单机版本锁定等需要指定固定机器的功能
* qschedule：主要涉及到执行节点手工上下线功能
* qmq：主要涉及到广播消费功能
* dubbo：主要涉及到服务单实例配置相关的功能

从上面可以看出，适配容器化的主要问题点在单机功能部分。单机功能适配的主要问题是随机 IP 和 hostname。为了解决这个问题，我们最初考虑了 2 个方案：

1. 引入一个唯一 ID 生成服务，为容器化应用的每个实例都产生一个固定 ID
2. 接受随机性，从功能层面上适配随机 IP

在综合考虑实现难度、运维复杂度、功能必要性、未来技术方向等各方面因素之后，我们决定选择接受随机性，从功能层面做适配和改造。不依赖一个唯一 ID 生成系统，整体的可靠性会更好。对各个系统中针对单机的功能进行分析后，发现大部分都可以做适配。容器化后的技术方向就是屏蔽单机，从服务维度考虑，因此那些不兼容的功能我们也可以从服务维度重新设计实现。

### 2.4 适配实践

#### 2.4.1 公共核心库容器化适配

公共核心库本身是由很多模块组成的，比如：

1. common-core，包括了应用接入、上下线管理、公共核心 API 等部分
2. common-web，针对 spring 环境的各种定制化增强功能模块
3. common-http，内部封装的 http client，添加了很多增强功能，比如外网访问代理、链路追踪接入等等。

公共核心库中最核心的功能就是 common-core 模块提供的应用身份及环境信息识别功能。common-core 模块会上报应用 token 数据和当前运行的机器环境数据到应用中心，应用中心会校验应用身份、环境等信息，通过后生成一个临时动态 token，最后会将 token 和应用环境信息再返回给 common-core。其他中间件和一些业务组件都会依赖 common-core 提供的 token 和环境信息。

这一次公共核心库容器化适配最关键的改动就是环境信息识别部分。在虚拟机环境中，公司机器的 hostname 是包含了环境、机房等信息的，所以 common-core 模块和应用中心依赖 IP 和 hostname 判定环境、机房信息，在容器化场景下这种做法就行不通了。同时，为了避免每个组件都自己判断当前是虚拟机环境还是容器化环境，核心库也得提供一个辨别具体环境的 API。

参考前面环境识别中描述的方案，common-core 中最重要的改动就是放弃从 hostname 中获取环境信息，转向读取机器上的服务器环境描述文件。应用中心上也是同理，不能再依赖 IP 反解获取 hostname，而是只能使用 common-core 中上报的信息。

#### 2.4.2 Dubbo 容器化适配

Dubbo 容器化适配的主要问题点有 2 个。一是单机配置相关的部分，包括上下线功能、业务单机配置等。二是公司内部开发的注册中心故障保护功能。下面会分别介绍这 2 个方面的详细适配方案。

这里，我们先简单介绍下公司内 dubbo 的服务注册与上下线功能。我们内部目前是使用 zookeeper 作为 dubbo 的注册中心，dubbo provider 启动后会在 zookeeper 注册，consumer 订阅 zookeeper 上的对应节点从而及时获取 provider 机器列表、动态配置等数据。原始的 dubbo 实现中，这里会遇到一个问题，provider 服务的注册是全自动的，代码初始化之后就会自己在 zookeeper 上写入节点信息，这时候 consumer 端就能够获取到最新数据并建立连接发送请求了。但是一种可能出现的问题场景是 provider 已经注册，应用却尚未启动完成，此时处理接收到的 consumer 端请求会报错。为了解决这个问题，我们引入了上下线机制。在 provider 注册到 zookeeper 上之前，我们会在 zookeeper 上的相应配置节点下写入一条下线配置，将这个节点提前标记为下线状态。等到应用收到上线信号后，我们会主动删除之前写入的下线配置，让 provider 节点上线。为了避免应用发布关闭时继续接收请求导致报错，我们也会在应用发布关闭前提前写入下线配置，让 provider 提前下线。

容器化之后，对于大多数业务方来说，dubbo 不做任何改动也能在容器化环境中正常提供服务注册、服务上下线、服务调用等核心功能。但是容器化环境中的随机 IP 还是会带来一些额外的问题。一是上下线机制加上频繁的 IP 变更会导致 zookeeper 上残留大量的过期数据，因为每次应用发布提前下线时都会写入一条下线记录。二是随机 IP 会导致和 IP 相关的配置失效，比如单机配置、路由配置等等。为了 zookeeper 服务的稳定性和 dubbo 功能的完整性，必须得针对容器化环境做相应的适配工作。

我们先介绍下容器化环境里的上下线方案。最初，考虑了两种解决容器化环境上下线的方案：

1. 修改 dubbo，让 provider 注册的数据延迟到最终上线时再写入
2. 修改上下线逻辑，将下线记录由永久节点改为临时节点，永久节点需要主动删除，临时节点应用关闭后就自动被 zookeeper 清除了

第一种方案涉及到修改 dubbo 本身的代码，整体会更加复杂。第二种只需要修改上下线部分的代码，这部分代码本身是作为插件形式存在的。我们最终选择了方案 2，主要是整体的代码修改量更少。

上下线配置都是临时性的，可以切换为临时节点。但是其他单机配置是不行的，因为很多配置是需要一直保留下去的。由于每次发布后都随机分配 IP，固定 IP 的单机配置发布后自然就失效了。最初，我们考虑整体方案是想要引入唯一 ID 生成系统来唯一标识某个单机，但是最终我们还是放弃了。一来引入唯一 ID 会带来额外的中心依赖，可靠性会降低。二来我们这边选择的发布模式是类似先扩容再缩容的模式，唯一 ID 也不好处理。目前我们是放弃了长期生效的单机配置，推荐业务使用整个服务级别的配置，这种级别长期看是更有好处的，避免了单机的不一致问题。

Dubbo 故障保护机制是我们为了避免 zookeeper 故障导致服务 provider 大量节点下线最终出现服务无法调用而开发的容错功能。正常情况下，如果 zookeeper 直接彻底挂掉，consumer 端的影响是不大的。但是我们历史上出现过 zookeeper 因为压力过大导致大量节点过期被清理掉的情况，这种情况下 consumer 端是有可能感知到 provider 大量下线的，此时很容易出现大量请求失败。因此我们设计实现了故障保护机制。当 consumer 发现 zookeeper 上存在的 provider 数量低于正常值的 35% 时，保护机制自动启用，consumer 会将所有预先缓存的 provider 视为正常的provider 进行调用。保护机制处于启用状态时，当 consumer 发现 zookeeper 上存在的 provider 数量大于等于正常值 75%，保护机制自动关闭，consumer 只会调用 zookeeper 上存在的 provider。Provider 数量正常值指最近 6 小时zookeeper 上存在过的 provider 数量，缓存的 provider 为最近 6 小时 zookeeper 上存在过的 provider。

容器化环境中先扩容再缩容的发布模式和 dubbo 故障保护机制刚好冲突了，发布批次少的应用很容易触发这个机制，导致业务日志中出现大量异常，但是实际上这个又并不会影响业务正常请求。针对这个功能，我们的改良点主要是两个。一是完整 provider 列表由累计最大改为瞬时最大，避免每次发布 provider 完整列表都翻倍，降低触发概率。二是触发 dubbo 故障保护功能后通过应用中心接口强制获取当前应用的完整在线容器列表，剔除掉确定下线的记录，避免大量报错。

#### 2.4.3 QMQ 容器化适配

QMQ 是公司内部开发的一个消息队列，目前已经开源，想要详细了解的话可以参考 https://github.com/qunarcorp/qmq。QMQ 容器化适配主要涉及了 3 个问题，这些问题也都是由随机 IP 和新发布模式导致。第一个问题是广播消费问题。第二个是大量过期数据的清理问题。第三个是使用持久消息和事务消息时的数据库授权问题。

QMQ 支持的消费模式和常见的 kafka 有些差异，所以这里我们先简单介绍下广播消费。QMQ 的消费进度都是是按消费组管理的，消费组内可以有一台或者多台机器，消息会被组内的消费者均分，增加组内的消费者数量就能提升消费能力。一般来说，大部分的业务消息都是希望多台机器均分消费的。不过也有一些场景中业务希望应用的每一台机器都能消费到主题的所有消息，比如触发本地缓存刷新的消息。广播消费就是针对这种场景设计的消费模式，在 QMQ 里实际上就是每个消费者都生成一个单独的消费组。

了解了广播消费的模式，大家应该很容易考虑到容器化后随机 IP 带来的问题，那就是广播消费的消费进度管理问题。在虚拟机环境中，机器是比较稳定的，无论是数量还是具体的 IP 等，这种场景下广播消费的进度是可以稳定管理的，每次应用重新启动都可以定位到之前的消费组并接着之前的消费进度继续消费。而容器化后，随机 IP 配合先扩容再缩容的发布模式，会导致广播消费的消费组非常不稳定，我们不得不重新考虑这种场景下消费进度该如何管理。

最初，为了解决广播消费消费进度管理的问题，我们也考虑采用固定 ID 生成服务。但仔细考虑后发现这样也还是不能满足要求，主要冲突的点在于发布模式的改变。采用固定 ID 的本意是发布时消费组的归属自动由老容器转移到新容器。但由于采用先扩容再缩容的发布模式，消费组归属自动转移就没法做了，因为发布时并行存在的消费组数量总是比正常情况下要多。这个问题我们纠结了挺久，后来才突然意识到一点：扩容缩容本身其实和广播消费不冲突。在虚拟机环境下，业务本身也是得扩容缩容的，这就说明业务本身使用广播消费时必然已经处理了扩容缩容带来的问题，否则他们自己的应用在虚拟机环境下也无法正常运作。所以我们最终放弃了固定 ID，完全接受随机 IP，将其当做扩容缩容场景对待。

广播消费接受了随机 IP，我们也要做相应的适配工作，除了 client 端根据环境做简单适配外，还有 2 个涉及到 QMQ 服务端的问题。第一个是随机数量变多，会产生很多过期数据。第二个是现有的消费进度默认实现会导致新消费组大量消费旧消息。第一个问题处理起来比较简单，梳理并增加相应的数据清理任务，加快清理频率就可以了。第二个问题是最初 QMQ 为了避免消费组先上线且主题后发送消息时依旧丢失最初发送的消息而设计的，让消费组默认从历史位置开始消费，这就导致容器化场景下每次发布广播消费的新机器都会变成从历史开始消费。但这里直接改成从最新位置消费很容易丢失消息，因为主题是发送消息时才分配具体的 QMQ 服务端节点，这就导致必然是先收到发送请求才能收到消费拉取请求。为了解决这个问题，我们调整了初始消费进度的判断算法，确定最初消费进度时额外考虑主题的创建时间，近期创建的从最旧开始，否则从最新位置开始。

为了给消息发送方提供更高的可靠性，QMQ 借助业务数据库提供了持久消息和事务消息。QMQ producer 支持发送消息前将消息先保存到业务数据库实例中，发送成功时自动删除，发送失败时从业务库里补偿发送，这就是持久消息。而事务消息则是在持久消息的基础上做了一致性增强，业务在数据库事务中发送的消息会等到事务成功提交后再发送，如果事务回滚则不会发出这条消息，这样业务的 DB 操作和消息发送就通过事务保持一致了。由于持久消息和事务消息都需要保存消息到业务数据库实例里，所以实际上数据库实例里会有一个 QMQ 专用的库，实例的使用方共享这个专用库，这里就会涉及到数据库访问权限的问题。容器化之前业务发送持久消息和事务消息时都需要在管理平台上提交上线申请，上线申请提交后会自动创建 QMQ 专用库，同时为业务机器授权。容器化带来的问题也就很明显了，随机 IP 导致数据库权限无法预先授权。这里的授权问题不仅仅是 QMQ 会遇到的，业务自己的 DB 授权也一样有这个问题，这个问题最终是引入了一个自动授权系统来解决，我们后面会详细介绍。

#### 2.4.4 其他组件容器化适配

剩余的各个中间件的改动就比较少了，主要都是一些单机功能的取舍问题。下面我们做一些简单介绍。
对于 qconfig，容器化适配主要是 2 个改动点。第一个是由于容器每次重启都会重建，所以容器环境下只好放弃 client 端本地配置缓存。第二个是放弃管理界面上针对单机的功能，改为组级别的模式，比如指定机器锁定版本、长期指定机器灰度配置等。

对于 qschedule，我们只是放弃了一些单机功能，比如指定任务的某些执行者下线功能。

## 3 DB 自动授权

公司里很多应用都需要使用数据库，线上应用访问数据库都需要提前申请权限，然后 DBA 按照机器维度进行授权。这种模式在容器化环境中无法继续使用，因为容器环境每次发布 IP 都会随机变化，并且无法提前知道 IP，因此无法提前申请机器级别的权限。同时 IP 变化速度加快，必须及时回收过期的权限，否则权限记录会不断膨胀。

从安全方面考虑，DBA 没有放开整个容器网络的访问限制，授权依旧需要按照 IP 级别进行。经过沟通，我们联合 CM 和 DBA 团队开发了自动授权服务，用来做容器环境下数据库的授权和回收。DB 自动授权系统按照应用管理数据库账号，根据外部的请求执行授权和回收操作。CM 团队负责让容器创建后自动触发授权操作，容器关闭时自动触发回收操作。DBA 团队负责将自动授权系统接入之前的权限管理体系中。

DB 自动授权系统的第一个重点功能是授权记录管理功能，需要根据将数据库授权记录组织到应用级别，同时对外提供对应的修改接口。授权记录中保存了账号名称、数据库表名称、账号权限等。同时为了保证安全，库中不能直接记录任何的命名密码，只能记录相应的密码 hash。授权记录的来源主要有 2 个。第一个是业务申请账号和权限后，DBA 的自动推送。第二个是业务提交 QMQ 上线申请后的自动推送。为了降低业务切换到容器的成本，我们做了一次初始数据导入，由 DBA 导出所有数据库实例中的单机授权记录，我们将这些授权记录转换整理为应用级别的授权记录并保存。

有了比较完善的授权记录后，下面就是权限的授予和回收了。在应用发布时，CM 增加了一个初始化容器，让 pod 创建后主动触发授权操作。Pod 销毁时则是主动触发回收操作。授权和回收时，请求会带着应用和 IP 信息，自动授权系统根据应用查找到所有的授权记录，然后遍历授权记录，由自动授权系统直连各个业务库执行指定 IP 和账号的授权或回收操作。这里的授予和回收都需要考虑幂等。授予操作本身是幂等的，重复执行不会有问题。回收操作不是幂等的，需要处理重复执行时的异常。

除了功能方面需要满足要求外，自动授权系统作为一个阻塞发布流程的应用，必须要提供足够的服务可靠性保证。我们做了以下措施来保证可靠性：

1. 授权记录同时在 DB 和 Redis 中保存，数据不过期。优先读 Redis，Redis 故障可以降级到数据库。数据库故障不影响授权，只影响新授权记录的推送。
2. 服务多机房部署，避免单机房故障。
3. 授权记录数据库多机房部署，避免数据库单机房故障。 
4. 限制单个数据库实例授权的并行度，避免高度并行影响授权效率

## 4. 总结

在整个中间件容器化适配过程中，我们的所有核心改动点都是围绕固定 IP 变为随机 IP 和发布模式变为先扩容再缩容这 2 个核心问题进行。在客户端组件中尽力屏蔽环境差异，保证客户端的兼容性。在服务端中屏蔽差异的同时适当放弃单机功能的支持，推动业务切换到基于应用环境维度的管理模式上。目前，公司内部已经完成了容器化切换过程，中间件无缝的支持为业务的切换提供了坚实的基础。
